# Résumé

Dans ce chapitre, nous avons abordé un large éventail de problèmes qui peuvent survenir dans les systèmes distribués, notamment :

- Chaque fois que vous essayez d'envoyer un paquet sur le réseau, il peut être perdu ou retardé arbitrairement. De même, la réponse peut être perdue ou retardée, donc si vous ne recevez pas de réponse, vous n'avez aucune idée si le message est passé.
- L'horloge d'un noeud peut être considérablement désynchronisée par rapport aux autres noeuds (malgré tous vos efforts pour configurer NTP), elle peut soudainement avancer ou reculer dans le temps, et il est dangereux de s'y fier car vous n'avez probablement pas une bonne mesure de l'intervalle d'erreur de votre horloge.
- Un processus peut se mettre en pause pendant un temps considérable à n'importe quel moment de son exécution (peut-être à cause d'un ramasse-miettes "stop-the-world"), être déclaré mort par d'autres noeuds, puis revenir à la vie sans se rendre compte qu'il était en pause.

Le fait que de telles défaillances partielles puissent se produire est la caractéristique essentielle des systèmes distribués. Chaque fois qu'un logiciel tente de faire quoi que ce soit en impliquant d'autres nœuds, il est possible qu'il échoue occasionnellement, qu'il ralentisse de manière aléatoire ou qu'il ne réponde pas du tout (et finisse par s'éteindre). Dans les systèmes distribués, nous essayons d'intégrer la tolérance aux défaillances partielles dans le logiciel, de sorte que le système dans son ensemble puisse continuer à fonctionner même si certains de ses éléments constitutifs sont cassés.

Pour tolérer les défaillances, la première étape consiste à les détecter, mais même cela est difficile. La plupart des systèmes ne disposent pas d'un mécanisme précis pour détecter si un nœud est tombé en panne, de sorte que la plupart des algorithmes distribués s'appuient sur des délais d'attente pour déterminer si un nœud distant est toujours disponible. Cependant, les délais d'attente ne peuvent pas faire la distinction entre les pannes de réseau et les pannes de nœud, et le retard variable du réseau fait qu'un nœud est parfois faussement soupçonné de tomber en panne. De plus, un nœud peut parfois se trouver dans un état dégradé : par exemple, une interface réseau Gigabit peut soudainement passer à un débit de 1 Kb/s en raison d'un bug du pilote [94]. Un tel nœud qui "boite" mais n'est pas mort peut être encore plus difficile à gérer qu'un nœud en panne.

Une fois qu'une défaillance est détectée, il n'est pas facile non plus de faire en sorte qu'un système la tolère : il n'y a pas de variable globale, pas de mémoire partagée, pas de connaissance commune ou tout autre type d'état partagé entre les machines. Les nœuds ne peuvent même pas se mettre d'accord sur l'heure qu'il est, et encore moins sur quelque chose de plus profond. La seule façon dont l'information peut circuler d'un nœud à l'autre est de l'envoyer sur un réseau peu fiable. Les décisions importantes ne peuvent être prises en toute sécurité par un seul nœud. Nous avons donc besoin de protocoles qui font appel à l'aide d'autres nœuds et tentent d'obtenir un quorum.

Si vous avez l'habitude d'écrire des logiciels dans la perfection mathématique idéalisée d'un ordinateur unique, où la même opération renvoie toujours le même résultat de manière déterministe, le passage à la réalité physique désordonnée des systèmes distribués peut être un peu choquant. Inversement, les ingénieurs en systèmes distribués considèrent souvent qu'un problème est trivial s'il peut être résolu sur un seul ordinateur [5], et en effet un seul ordinateur peut faire beaucoup de choses de nos jours [95]. Si vous pouvez éviter d'ouvrir la boîte de Pandore et simplement garder les choses sur une seule machine, cela vaut généralement la peine de le faire.

Cependant, comme nous l'avons vu dans l'introduction de la partie II, l'évolutivité n'est pas la seule raison de vouloir utiliser un système distribué. La tolérance aux pannes et la faible latence (en plaçant les données géographiquement proches des utilisateurs) sont des objectifs tout aussi importants, et ces éléments ne peuvent être atteints avec un seul nœud.

Dans ce chapitre, nous avons également pris quelques tangentes pour explorer si le manque de fiabilité des réseaux, des horloges et des processus est une loi inévitable de la nature. Nous avons vu que ce n'était pas le cas : il est possible de donner des garanties de réponse en temps réel et des retards limités dans les réseaux, mais cela est très coûteux et entraîne une utilisation moindre des ressources matérielles. La plupart des systèmes non critiques pour la sécurité préfèrent les systèmes bon marché et peu fiables aux systèmes coûteux et fiables.

Nous avons également évoqué les superordinateurs, qui supposent des composants fiables et doivent donc être arrêtés et redémarrés entièrement lorsqu'un composant tombe en panne. En revanche, les systèmes distribués peuvent fonctionner éternellement sans être interrompus au niveau du service, car toutes les pannes et la maintenance peuvent être gérées au niveau du nœud, du moins en théorie. (En pratique, si un mauvais changement de configuration est déployé sur tous les nœuds, cela mettra quand même un système distribué à genoux).

Ce chapitre n'a parlé que de problèmes et nous a donné des perspectives peu réjouissantes. Dans le prochain chapitre, nous passerons aux solutions et discuterons de certains algorithmes qui ont été conçus pour faire face à tous les problèmes des systèmes distribués. 
